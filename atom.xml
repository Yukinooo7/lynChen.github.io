<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yukino</title>
  
  <subtitle>SURF</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.yukino424.cn/"/>
  <updated>2019-07-19T13:32:31.523Z</updated>
  <id>https://www.yukino424.cn/</id>
  
  <author>
    <name>Lingyun</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>No Game No Life 0</title>
    <link href="https://www.yukino424.cn/2019/07/19/no-name-no-life-zero/"/>
    <id>https://www.yukino424.cn/2019/07/19/no-name-no-life-zero/</id>
    <published>2019-07-19T13:02:31.000Z</published>
    <updated>2019-07-19T13:32:31.523Z</updated>
    
    <content type="html"><![CDATA[<p>空白に败北の二文字はない！</p><a id="more"></a><p>9102年了，松冈爱衣还是没有在一起<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f62e.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62e.png?v8">😮</span></p><p>No game no life<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png?v8">😊</span><br>Bilibili: <a href="https://www.bilibili.com/bangumi/media/md184/?from=search&seid=16888925639102359689" target="_blank" rel="noopener">https://www.bilibili.com/bangumi/media/md184/?from=search&seid=16888925639102359689</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;空白に败北の二文字はない！&lt;/p&gt;
    
    </summary>
    
      <category term="Anime" scheme="https://www.yukino424.cn/categories/Anime/"/>
    
    
      <category term="Hobby" scheme="https://www.yukino424.cn/tags/Hobby/"/>
    
  </entry>
  
  <entry>
    <title>20190719 work report</title>
    <link href="https://www.yukino424.cn/2019/07/19/20190719-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/19/20190719-work-report/</id>
    <published>2019-07-19T12:30:22.000Z</published>
    <updated>2019-07-19T12:56:40.095Z</updated>
    
    <content type="html"><![CDATA[<p>参考网上的例子建了个python文件用来获取USB的视频，并且截图保存到指定文件夹<br><i class="fa fa-github"></i> Github: <a href="https://github.com/Yukinooo7/Image-processing" target="_blank" rel="noopener">https://github.com/Yukinooo7/Image-processing</a></p><a id="more"></a><h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><p>从摄像头逐帧读入图片并展示</p><h1 id="Python-Library"><a href="#Python-Library" class="headerlink" title="Python Library"></a>Python Library</h1><ol><li>OPENCV</li><li>NUMPY</li></ol><h1 id="获取摄像头"><a href="#获取摄像头" class="headerlink" title="获取摄像头"></a>获取摄像头</h1><h2 id="VideoCapture里面的序号"><a href="#VideoCapture里面的序号" class="headerlink" title="VideoCapture里面的序号"></a>VideoCapture里面的序号</h2><h3 id="0-：Default-camera"><a href="#0-：Default-camera" class="headerlink" title="0 ：Default camera"></a>0 ：Default camera</h3><h3 id="1-USB-camera-2"><a href="#1-USB-camera-2" class="headerlink" title="1 : USB camera 2"></a>1 : USB camera 2</h3><h3 id="2-USB-camera-3"><a href="#2-USB-camera-3" class="headerlink" title="2 : USB camera 3"></a>2 : USB camera 3</h3><h3 id="1-The-latest-camera"><a href="#1-The-latest-camera" class="headerlink" title="-1 : The latest camera"></a>-1 : The latest camera</h3><hr><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 若不加cv2.CAP_DSHOW，会报错</span><br><span class="line">cap = cv2.VideoCapture(1,cv2.CAP_DSHOW)</span><br><span class="line"># 画面宽度设为640</span><br><span class="line">cap.set(cv2.CAP_PROP_FRAME_WIDTH,640)</span><br><span class="line"># 画面长度设为320</span><br><span class="line">cap.set(cv2.CAP_PROP_FRAME_HEIGHT,320)</span><br><span class="line"># 设置一个名为images的窗口，窗口大小为画面大小</span><br><span class="line">cv2.namedWindow('images',cv2.WINDOW_AUTOSIZE)</span><br></pre></td></tr></tbody></table></figure><hr><h1 id="截图"><a href="#截图" class="headerlink" title="截图"></a>截图</h1><p><strong>截图并且用月日小时分钟作为文件名保存</strong></p><hr><h2 id="Code-1"><a href="#Code-1" class="headerlink" title="Code"></a>Code</h2><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img_name = "{}.jpg".format(time.strftime("%m%d%H%M",time.localtime()))</span><br><span class="line">cv2.imwrite(img_name,frame)</span><br><span class="line">cv2.imshow(img_name,frame)</span><br><span class="line">print("{}.jpg".format(time.strftime("%m%d%H%M",time.localtime()))+"has been saved")</span><br></pre></td></tr></tbody></table></figure><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>可以替代ViewPlayCap进行操作，对后面的操作有一定帮助。</p><hr><h1 id="Future-Plan"><a href="#Future-Plan" class="headerlink" title="Future Plan"></a>Future Plan</h1><p>可以每隔一段时间进行截图，并对截图进行分析，可以作为判断是否出现错误的依据。希望<strong>Xunjieliu</strong>可以优化一下<i class="fa fa-cloud"></i></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考网上的例子建了个python文件用来获取USB的视频，并且截图保存到指定文件夹&lt;br&gt;&lt;i class=&quot;fa fa-github&quot;&gt;&lt;/i&gt; Github: &lt;a href=&quot;https://github.com/Yukinooo7/Image-processing&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/Yukinooo7/Image-processing&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python code" scheme="https://www.yukino424.cn/categories/Python-code/"/>
    
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>20190718 work report</title>
    <link href="https://www.yukino424.cn/2019/07/18/20190718-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/18/20190718-work-report/</id>
    <published>2019-07-18T02:39:58.000Z</published>
    <updated>2019-07-18T14:58:33.875Z</updated>
    
    <content type="html"><![CDATA[<p>Today experimental images</p><a id="more"></a><h1 id="Observe-the-Taylor-Cone"><a href="#Observe-the-Taylor-Cone" class="headerlink" title="Observe the Taylor Cone"></a>Observe the Taylor Cone</h1><h2 id="置于stage的右侧"><a href="#置于stage的右侧" class="headerlink" title="置于stage的右侧"></a>置于stage的右侧</h2><p>效果不佳，锥形太小，无效图像太多，包括支架和针头。并且，光源不集中，泰勒锥受光不均匀，处理难度较高</p><p><img src="/images/20190718/07181041.jpg" alt></p><h2 id="stage上面更靠近nozzle"><a href="#stage上面更靠近nozzle" class="headerlink" title="stage上面更靠近nozzle"></a>stage上面更靠近nozzle</h2><p>简单说，缺个灯，<strong>@Xunjieliu</strong></p><p><img src="/images/20190718/07181134.jpg" alt><br><img src="/images/20190718/07181145.jpg" alt><br><img src="/images/20190718/07181208.jpg" alt></p><h2 id="Camera-Position"><a href="#Camera-Position" class="headerlink" title="Camera Position"></a>Camera Position</h2><p><img src="/images/20190718/lateral_camera.jpg" alt></p><hr><h1 id="Observe-the-Scaffold"><a href="#Observe-the-Scaffold" class="headerlink" title="Observe the Scaffold"></a>Observe the Scaffold</h1><h2 id="L1000拍摄效果良好，但由于精度太高，调焦时间过长，固定后该情况可以解决"><a href="#L1000拍摄效果良好，但由于精度太高，调焦时间过长，固定后该情况可以解决" class="headerlink" title="L1000拍摄效果良好，但由于精度太高，调焦时间过长，固定后该情况可以解决"></a>L1000拍摄效果良好，但由于精度太高，调焦时间过长，固定后该情况可以解决</h2><p><strong>样品</strong><br><img src="/images/20190718/07181114.jpg" alt><br><img src="/images/20190718/07181216.jpg" alt><br><img src="/images/20190718/07181217.jpg" alt></p><p><strong>Camera position</strong><br><img src="/images/20190718/vertical_camera.jpg" alt></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Today experimental images&lt;/p&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Experiment" scheme="https://www.yukino424.cn/tags/Experiment/"/>
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>20190717 work report</title>
    <link href="https://www.yukino424.cn/2019/07/17/20190717-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/17/20190717-work-report/</id>
    <published>2019-07-17T08:48:53.000Z</published>
    <updated>2019-07-17T10:58:24.564Z</updated>
    
    <content type="html"><![CDATA[<p>讨论了一下关于研究的方向，是以研究为目的，还是以开发一款实用软件为目的。<br>如果是以研究为目的，那么可能是处理某一个特例<br>如果是以实用软件为目的，那么需要考虑所有的例子</p><h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><p>Construct a stable setup to get the high quality images and ensure that the position of the nozzle is fixed.</p><a id="more"></a><p>Today we check another printing setup and find it has constrcuted the stable shooting enviroment.</p><h1 id="Comparison-between-two-device"><a href="#Comparison-between-two-device" class="headerlink" title="Comparison between two device"></a>Comparison between two device</h1><h2 id="Another-Lab-setup"><a href="#Another-Lab-setup" class="headerlink" title="Another Lab setup"></a>Another Lab setup</h2><p>Compared with our setup, this camera is much closer to the Taylor Cone because it shoots Taylor cone obliquely. This camera can take clear Taylor cone but it cannot ignore the scaffold.</p><p><strong>Camera position</strong></p><h2 id><a href="#" class="headerlink" title></a><img src="/images/20190717/camera_position_c.jpg" alt></h2><h2 id="Our-Lab-setup"><a href="#Our-Lab-setup" class="headerlink" title="Our Lab setup"></a>Our Lab setup</h2><p>As for our setup, we can take pictures without scaffold which is easy to process but we cannot put the camera on the much closer position due to the moveable stage. Therefore, we cannot shoot clear Taylor cone with small nozzle because most backgrounds are useless which contains a large part of nozzle.  </p><h1 id="Images-from-two-device"><a href="#Images-from-two-device" class="headerlink" title="Images from two device"></a>Images from two device</h1><h2 id="An-ideal-image"><a href="#An-ideal-image" class="headerlink" title="An ideal image"></a>An ideal image</h2><p><img src="/images/20190717/07171157.jpg" alt></p><h2 id="Our-image"><a href="#Our-image" class="headerlink" title="Our image"></a>Our image</h2><p><img src="/images/20190712/L10_nozzle.jpg" alt></p><p>#TODO<br>If we can guarantee the position of camera is fixed, image processing will be much easier. </p><h1 id="Two-ideas-to-get-only-the-Taylor-cone"><a href="#Two-ideas-to-get-only-the-Taylor-cone" class="headerlink" title="Two ideas to get only the Taylor cone"></a>Two ideas to get only the Taylor cone</h1><h2 id="Manual-screenshot"><a href="#Manual-screenshot" class="headerlink" title="Manual screenshot"></a>Manual screenshot</h2><p>This method allows user to select which area they want to capture.</p><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#img is the origin image</span></span><br><span class="line">cv2.namedWindow(<span class="string">"image"</span>, flags= cv2.WINDOW_NORMAL | cv2.WINDOW_FREERATIO)</span><br><span class="line">cv2.namedWindow(<span class="string">"image_roi"</span>, flags= cv2.WINDOW_NORMAL | cv2.WINDOW_FREERATIO)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">"image"</span>, img)</span><br><span class="line"><span class="comment"># 是否显示网格 </span></span><br><span class="line">showCrosshair = <span class="literal">True</span></span><br><span class="line"><span class="comment"># 如果为Ture的话 , 则鼠标的其实位置就作为了roi的中心</span></span><br><span class="line"><span class="comment"># False: 从左上角到右下角选中区域</span></span><br><span class="line">fromCenter = <span class="literal">False</span></span><br><span class="line"><span class="comment"># Select ROI manually </span></span><br><span class="line">rect = cv2.selectROI(<span class="string">"image"</span>, img, showCrosshair, fromCenter)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"选中矩形区域"</span>)</span><br><span class="line">(x, y, w, h) = rect</span><br><span class="line"></span><br><span class="line"><span class="comment"># Crop image</span></span><br><span class="line">imCrop = img[y : y+h, x:x+w]</span><br></pre></td></tr></tbody></table></figure><h3 id="Sample-result"><a href="#Sample-result" class="headerlink" title="Sample result"></a>Sample result</h3><p><strong>Origin</strong><br><img src="/images/20190717/nozzle.png" alt></p><hr><p><strong>After processing</strong><br><img src="/images/20190717/processed_nozzle.png" alt></p><p><strong>Screenshot</strong><br><img src="/images/20190717/image_roi.png" alt></p><hr><p><strong>After processing</strong><br><img src="/images/20190717/processed_image_roi_m.png" alt></p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>We can easily find that the screenshot one has less noise and do not require further processing to remove the noise.</p><h2 id="Automically-screenshot"><a href="#Automically-screenshot" class="headerlink" title="Automically screenshot"></a>Automically screenshot</h2><p>This method can be implemented iff the camera and nozzle is fixed. This can promise the position of nozzle is fixed so we can capture the Taylor cone part.</p><h3 id="Code-1"><a href="#Code-1" class="headerlink" title="Code"></a>Code</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'roi.jpg'</span>)</span><br><span class="line">roi = img1[<span class="number">0</span>:rows, <span class="number">0</span>:cols ]</span><br></pre></td></tr></tbody></table></figure><h3 id="Sample-result-1"><a href="#Sample-result-1" class="headerlink" title="Sample result"></a>Sample result</h3><p><img src="/images/20190717/processed_image_roi_a.png" alt></p><h3 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>This method is hard to locate the position of the Taylor cone.</p><h2 id="Conclusion-2"><a href="#Conclusion-2" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>I prefer to use the manual one to process the image but I need your help in optimize the code to transfer the manual function into automatical function. However, after screenshot, the processed image will contain a rectangular border.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;讨论了一下关于研究的方向，是以研究为目的，还是以开发一款实用软件为目的。&lt;br&gt;如果是以研究为目的，那么可能是处理某一个特例&lt;br&gt;如果是以实用软件为目的，那么需要考虑所有的例子&lt;/p&gt;
&lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;p&gt;Construct a stable setup to get the high quality images and ensure that the position of the nozzle is fixed.&lt;/p&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Experiment" scheme="https://www.yukino424.cn/tags/Experiment/"/>
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Camera position</title>
    <link href="https://www.yukino424.cn/2019/07/16/camera-position/"/>
    <id>https://www.yukino424.cn/2019/07/16/camera-position/</id>
    <published>2019-07-16T10:00:01.000Z</published>
    <updated>2019-07-16T10:10:56.081Z</updated>
    
    <content type="html"><![CDATA[<p>上次做PRE的时候老师觉得拍照看不出来摄像头的位置，专门去学了如何用Ai CC画图，但总觉得，会不会有点丑？</p><a id="more"></a><hr><h1 id="Camera-Position-Picture"><a href="#Camera-Position-Picture" class="headerlink" title="Camera Position Picture"></a>Camera Position Picture</h1><p><img src="/images/two_cameras_position.png" alt></p><p>右边的摄像头与针头还有左边的摄像头平行，这样的话，背景是已知得，可能图片会好处理一点，左边的摄像头，固定在放置针头的支架上。</p><hr><h1 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h1><p>首先还是光源的问题，通过上周的测试，我觉得用摄像头自带的前置LED灯，拍出来的效果比较好。但L100的灯分布不太均匀，相比而言，L1000的灯拍出来的效果就很好。<br>如果有需要的话，可能还<strong>需要买一个手电筒</strong></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上次做PRE的时候老师觉得拍照看不出来摄像头的位置，专门去学了如何用Ai CC画图，但总觉得，会不会有点丑？&lt;/p&gt;
    
    </summary>
    
    
      <category term="Image" scheme="https://www.yukino424.cn/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>20190714 work report</title>
    <link href="https://www.yukino424.cn/2019/07/14/20190714-work-report-1/"/>
    <id>https://www.yukino424.cn/2019/07/14/20190714-work-report-1/</id>
    <published>2019-07-14T11:14:08.000Z</published>
    <updated>2019-07-16T06:36:45.140Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><p>Processed the Taylor cone into profile drawing</p><a id="more"></a><hr><h1 id="method"><a href="#method" class="headerlink" title="method"></a>method</h1><ol><li>Use Python library numpy and opencv to detect the profile of the </li></ol><hr><ol start="2"><li>the Taylor Cone. </li></ol><hr><ol start="3"><li>Change threshold differs from Taylor Cone categories. </li></ol><hr><ol start="4"><li>Rewrite the detection result on the another white image. </li></ol><hr><ol start="5"><li>Add a short nozzle above Taylor Cone</li></ol><hr><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><h2 id="Broken"><a href="#Broken" class="headerlink" title="Broken"></a>Broken</h2><p><img src="/images/20190714/Broken.jpg" alt></p><hr><h2 id="Tiny"><a href="#Tiny" class="headerlink" title="Tiny"></a>Tiny</h2><p><img src="/images/20190714/Tiny.jpg" alt></p><hr><h2 id="Discharge"><a href="#Discharge" class="headerlink" title="Discharge"></a>Discharge</h2><p><img src="/images/20190714/Discharge.jpg" alt></p><hr><h2 id="Meniscus"><a href="#Meniscus" class="headerlink" title="Meniscus"></a>Meniscus</h2><p><img src="/images/20190714/Meniscus.jpg" alt></p><hr><h2 id="Huge"><a href="#Huge" class="headerlink" title="Huge"></a>Huge</h2><p><img src="/images/20190714/Huge.jpg" alt></p><hr><h2 id="Multijet"><a href="#Multijet" class="headerlink" title="Multijet"></a>Multijet</h2><p><img src="/images/20190714/Multijet.jpg" alt></p><hr><h2 id="Dry"><a href="#Dry" class="headerlink" title="Dry"></a>Dry</h2><p><img src="/images/20190714/Dry.jpg" alt></p><hr><h2 id="Standard"><a href="#Standard" class="headerlink" title="Standard"></a>Standard</h2><p><img src="/images/20190714/Standard.jpg" alt></p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;p&gt;Processed the Taylor cone into profile drawing&lt;/p&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>20190712 work report</title>
    <link href="https://www.yukino424.cn/2019/07/12/20190712-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/12/20190712-work-report/</id>
    <published>2019-07-12T00:49:10.000Z</published>
    <updated>2019-07-17T11:01:49.919Z</updated>
    
    <content type="html"><![CDATA[<p>We only took some pictures with different light today because our new camera’s lens is broken.</p><a id="more"></a><h1 id="L10"><a href="#L10" class="headerlink" title="L10"></a>L10</h1><p><img src="/images/20190712/L10_nozzle.jpg" alt="L10 nozzle"><br><img src="/images/20190712/L10_scaffold.jpg" alt="L10 scaffold"></p><hr><h1 id="L100"><a href="#L100" class="headerlink" title="L100"></a>L100</h1><p><img src="/images/20190712/L100.jpg" alt></p><hr><h1 id="L1000"><a href="#L1000" class="headerlink" title="L1000"></a>L1000</h1><p><img src="/images/20190712/L1000.jpg" alt></p><hr><h1 id="External-Light"><a href="#External-Light" class="headerlink" title="External Light"></a>External Light</h1><p><img src="/images/20190712/external.jpg" alt></p><hr><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Compared with other images, L1000’s image is the best image and L10 is the also Ok but the light looks uneven. Therefore, we think the default light is the best light which is in front of lens. But we may buy another light for shooting better images. </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;We only took some pictures with different light today because our new camera’s lens is broken.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Image" scheme="https://www.yukino424.cn/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>20190705 work report</title>
    <link href="https://www.yukino424.cn/2019/07/05/20190705-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/05/20190705-work-report/</id>
    <published>2019-07-05T11:14:08.000Z</published>
    <updated>2019-07-19T13:01:38.563Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><p><strong>Lab</strong>: Take more clear and high quality images and process them<br><strong>Afternoon</strong>: Integrate the processed images for two weeks and prepare the PPT</p><a id="more"></a><hr><h1 id="Reason"><a href="#Reason" class="headerlink" title="Reason"></a>Reason</h1><p>On this Wednesday, we tried to take the scaffold pictures from its right side vertically but the result didn’t reach our expectation.</p><hr><p><strong>Light Position</strong><br><img src="/images/20190705/light_position.jpg" alt="Light Position"></p><hr><p><strong>Scaffold</strong><br><img src="/images/20190705/scaffold_07010525.jpg" alt></p><hr><p><strong>Final Processed image</strong><br><img src="/images/20190705/canny_gaussian.jpg" alt></p><hr><p>We can find that the scaffold image looks a little bad because the light looks unevenly. It leads to the bad processed result. We do not detect any edge inside scaffold but the Canny operator processed the image automatically which generate an edge inside the scaffold.<br>Therefore, today, we decide to find better light positions and take clear pictures with high light intensity.</p><hr><h1 id="Today-work"><a href="#Today-work" class="headerlink" title="Today work"></a>Today work</h1><p>Last time, we moved the stage to the right side as shown in the Figure 1. But we were not satisfied with the result so this time we decide to move the stage to the left side as shown in Figure 4.</p><h3 id="The-First-Light-Position"><a href="#The-First-Light-Position" class="headerlink" title="The First Light Position"></a>The First Light Position</h3><p><strong>Figure 4</strong><br><img src="/images/20190705/left_light_position.jpg" alt></p><hr><p>At the first time, we set the light on the left position of above the scaffold.</p><p><strong>Scaffold</strong><br><img src="/images/20190705/07051054.jpg" alt></p><hr><p>This time the scaffold is very clear and light. Also, we can see the pore clearly.</p><p><img src="/images/20190705/07051054_canny_gaussian.jpg" alt></p><hr><p>The pores are easy to find out and this image is easier to process for the further process.</p><hr><h3 id="The-Second-Light-Position"><a href="#The-Second-Light-Position" class="headerlink" title="The Second Light Position"></a>The Second Light Position</h3><p><img src="/images/20190705/right_light_position.jpg" alt></p><hr><p>We can find that this light position looks dangerous and uneasy to fix.<br>Also, the pictures looks worse than the first one.</p><p><strong>Scaffold</strong><br><img src="/images/20190705/07051045.jpg" alt></p><hr><p><strong>Final processed image result</strong><br><img src="/images/20190705/07051045_canny_gaussian.jpg" alt></p><hr><p>We can find that the pores in this images looks irregular and uneven. </p><hr><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p><strong>Therefore, now we think the right light above the right is the best light position.</strong></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Lab&lt;/strong&gt;: Take more clear and high quality images and process them&lt;br&gt;&lt;strong&gt;Afternoon&lt;/strong&gt;: Integrate the processed images for two weeks and prepare the PPT&lt;/p&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Experiment" scheme="https://www.yukino424.cn/tags/Experiment/"/>
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>20190703 work report</title>
    <link href="https://www.yukino424.cn/2019/07/03/20190703-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/03/20190703-work-report/</id>
    <published>2019-07-03T08:53:57.000Z</published>
    <updated>2019-07-16T09:10:21.224Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><p>Consider the Gaussian Blur and Canny Operator for edge detection. </p><a id="more"></a><h1 id="Compare-Gaussian-Blur-and-Median-Blur"><a href="#Compare-Gaussian-Blur-and-Median-Blur" class="headerlink" title="Compare Gaussian Blur and Median Blur."></a>Compare Gaussian Blur and Median Blur.</h1><h2 id="Gaussian-Blur"><a href="#Gaussian-Blur" class="headerlink" title="Gaussian Blur"></a>Gaussian Blur</h2><p><strong>Original image</strong><br><img src="/images/20190703/scaffold_07010525.jpg" alt="scaffold_07010525.jpg"><br><strong>Grayscale</strong><br><img src="/images/20190703/gray.jpg" alt="gray.jpg"></p><p><strong>Gaussian Blur</strong><br><img src="/images/20190703/gaussian_blur.jpg" alt="gaussian_blur.jpg"></p><p><strong>Canny Operator</strong><br><img src="/images/20190703/canny_gaussian.jpg" alt="canny_gaussian.jpg"></p><hr><h2 id="Median-Blur"><a href="#Median-Blur" class="headerlink" title="Median Blur"></a>Median Blur</h2><p><strong>Median Blur</strong><br><img src="/images/20190703/median_blur.jpg" alt="median_blur.jpg"></p><hr><p><strong>Canny Operator</strong><br><img src="/images/20190703/canny_median.jpg" alt="canny_median.jpg"></p><p>Compared to Gaussian Blur, the pores cannot be seen clearly which is not what we expected. </p><hr><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Therefore, we decide to use Gaussian Blur to reduce the noise and maybe use median blur for Taylor<br>cone detection.</p><hr><h1 id="Tomorrow-Target"><a href="#Tomorrow-Target" class="headerlink" title="Tomorrow Target:"></a>Tomorrow Target:</h1><p>Pay more attention on images.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;p&gt;Consider the Gaussian Blur and Canny Operator for edge detection. &lt;/p&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>20190702 work report</title>
    <link href="https://www.yukino424.cn/2019/07/02/20190702-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/02/20190702-work-report/</id>
    <published>2019-07-02T08:06:28.000Z</published>
    <updated>2019-07-16T08:20:25.692Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><ol><li>processing the printing images</li><li>After pre-processed the pictures, we found that the quality of the images depends on the position and intenity of the light.</li></ol><a id="more"></a><hr><h1 id="Image-processing"><a href="#Image-processing" class="headerlink" title="Image processing"></a>Image processing</h1><p><strong>60% PCL scaffold</strong><br><img src="/images/20190702/scaffold_07010525.jpg" alt></p><hr><p><strong>Gray</strong><br><img src="/images/20190702/gray.jpg" alt></p><hr><p><strong>Binarization</strong><br><img src="/images/20190702/processed_auto.jpg" alt></p><hr><p>According to these pictures, we can found that it is hard to recognize pores inside the scaffold, and<br>we think the main reason is because of the light position. Wrong light position leads to the bad<br>images which is hard to process. Therefore, we are considering the position of the light and we will<br>buy a new light to meet our shoot requirement.</p><hr><h1 id="Light-position-consideration"><a href="#Light-position-consideration" class="headerlink" title="Light position consideration"></a>Light position consideration</h1><p><img src="/images/light_position.jpg" alt></p><p>The processed pictures was took under this situation but we still think there will be a better position<br>to set the light.</p><hr><h1 id="Concluion"><a href="#Concluion" class="headerlink" title="Concluion"></a>Concluion</h1><ol><li><p>Required equipment:</p></li><li><p>One or more lights</p></li><li><p>At least one camera (super-eyes B011 can shoot our required pictures if we provides better light (suppose))</p></li></ol><hr><h1 id="Tomorrow-target"><a href="#Tomorrow-target" class="headerlink" title="Tomorrow target"></a>Tomorrow target</h1><ol><li><p>Considering about the light position</p></li><li><p>Optimize the light for better pictures</p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;processing the printing images&lt;/li&gt;
&lt;li&gt;After pre-processed the pictures, we found that the quality of the images depends on the position and intenity of the light.&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Experiment" scheme="https://www.yukino424.cn/tags/Experiment/"/>
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>20190701 work report</title>
    <link href="https://www.yukino424.cn/2019/07/01/20190701-work-report/"/>
    <id>https://www.yukino424.cn/2019/07/01/20190701-work-report/</id>
    <published>2019-07-01T07:52:28.000Z</published>
    <updated>2019-07-16T08:51:54.781Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><ol><li><p>take more and better images on the same two positions as yesterday</p></li><li><p>take pictures with better background<br>Horizon: √<br>Vertical: √</p></li></ol><a id="more"></a><hr><h1 id="Tomorrow-Target"><a href="#Tomorrow-Target" class="headerlink" title="Tomorrow Target"></a>Tomorrow Target</h1><p>Implement image pre-processing algorithms</p><ol><li>Subtract</li><li>Sharpen</li><li>Edge connection</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;take more and better images on the same two positions as yesterday&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;take pictures with better background&lt;br&gt;Horizon: √&lt;br&gt;Vertical: √&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Experiment" scheme="https://www.yukino424.cn/tags/Experiment/"/>
    
  </entry>
  
  <entry>
    <title>20190630 work report</title>
    <link href="https://www.yukino424.cn/2019/06/30/20190630-work-report/"/>
    <id>https://www.yukino424.cn/2019/06/30/20190630-work-report/</id>
    <published>2019-06-30T07:27:19.000Z</published>
    <updated>2019-07-16T08:02:55.113Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><p>Sufficient data collection including background and Taylor cone, background and scaffold.</p><hr><h1 id="Experiment-plan"><a href="#Experiment-plan" class="headerlink" title="Experiment plan"></a>Experiment plan</h1><ol><li>Help xunjie to be familiar with the setup and printing procedure</li><li>Consider possible positions of the second camera</li></ol><a id="more"></a><hr><h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><p>First camera observes the Taylor cone horizontally and the second camera observes the scaffold vertically.</p><hr><h2 id="Horizontally-executable"><a href="#Horizontally-executable" class="headerlink" title="Horizontally: executable"></a>Horizontally: executable</h2><p><strong>Background with nozzle</strong><br><img src="/images/20190630/with_nozzle.jpg" alt></p><hr><p><strong>Background only</strong><br><img src="/images/20190630/without_nozzle.jpg" alt></p><hr><p><strong>Nozzle extraction normal sample without applied electrical field</strong><br><img src="/images/20190630/nozzle_extraction_normal_sample.jpg" alt></p><hr><p><strong>Nozzle extraction 01 sample without applied electrical field</strong><br><img src="/images/20190630/nozzle_extraction_01_sample.jpg" alt></p><hr><h2 id="Vertically-X"><a href="#Vertically-X" class="headerlink" title="Vertically: X"></a>Vertically: X</h2><p>the stage movement has a range from -50 to 50, so the scaffold cannot move as we expected. </p><p>However, when it moves for the leftmost position, we can use a lateral camera to take a photo. </p><hr><p><strong>Some image samples</strong><br><img src="/images/20190630/lateral_scaffold_06300454.jpg" alt><br><img src="/images/20190630/lateral_scaffold_06300504.jpg" alt><br><img src="/images/20190630/lateral_scaffold_06300510.jpg" alt></p><hr><p>But we don’t have any idea about how to classify these pictures.<br>Also, we want to get the sample scaffold and use that as the training material.<br>Decide to use which shooting software to take some photos for testing</p><h1 id="Possible-Camera-positions"><a href="#Possible-Camera-positions" class="headerlink" title="Possible Camera positions"></a>Possible Camera positions</h1><h2 id="Horizontally"><a href="#Horizontally" class="headerlink" title="Horizontally"></a>Horizontally</h2><p><img src="/images/20190630/camera_position_b.jpg" alt></p><h2 id="Vertically"><a href="#Vertically" class="headerlink" title="Vertically"></a>Vertically</h2><p><img src="/images/20190630/camera_position_a.jpg" alt></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Target&quot;&gt;&lt;a href=&quot;#Target&quot; class=&quot;headerlink&quot; title=&quot;Target&quot;&gt;&lt;/a&gt;Target&lt;/h1&gt;&lt;p&gt;Sufficient data collection including background and Taylor cone, background and scaffold.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;Experiment-plan&quot;&gt;&lt;a href=&quot;#Experiment-plan&quot; class=&quot;headerlink&quot; title=&quot;Experiment plan&quot;&gt;&lt;/a&gt;Experiment plan&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Help xunjie to be familiar with the setup and printing procedure&lt;/li&gt;
&lt;li&gt;Consider possible positions of the second camera&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Work report" scheme="https://www.yukino424.cn/categories/Work-report/"/>
    
    
      <category term="Experiment" scheme="https://www.yukino424.cn/tags/Experiment/"/>
    
      <category term="Image processing" scheme="https://www.yukino424.cn/tags/Image-processing/"/>
    
      <category term="Python" scheme="https://www.yukino424.cn/tags/Python/"/>
    
  </entry>
  
</feed>
